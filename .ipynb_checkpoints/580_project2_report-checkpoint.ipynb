{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2 - Team Hot Dog\n",
    "\n",
    "Dongru Jia: Model 2, Design Poster  \n",
    "Jianhao Ji: Model 1, Data Cleaning  \n",
    "Miao Wang: Model 1, Data Cleaning  \n",
    "Yuxuan Yao: Model 2, Pring Poster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import string\n",
    "import csv\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset are from Kaggle.com, which includes more than 4800 movies from The Movie Database (TMDB). Features include movie title, tagline, genres, overview, keywords, cast,  audience ratings, popularity, vote count and etc. Among them, several important variables are listed as below:\n",
    " \n",
    "Columns in ‘Tmdb_5000_credits.csv’:\n",
    "Title: Movie name - System return label, \n",
    "Cast: Cast and character list - Potential model feature, \n",
    "Crew: Firm crew team - Potential model feature\n",
    " \n",
    "Columns in ‘Tmdb_5000_movies.csv’:\n",
    "Genres: Movie type - Feature or label in two recommendation models, \n",
    "Keywords: Views summarized movie keywords - Model feature, \n",
    "Overview: Brief movie summary - Model feature, \n",
    "Popularity: Movie popularity - Ranking conference for return labels, \n",
    "Production_ companies: Movie production companies - Model feature, \n",
    "Title: Movie name - System return label, \n",
    "Vote_average: Viewer overall vote score - Final return table display\n",
    "\n",
    "In order to prepare our data for further analysis, we combined the columns of keywords, genres, comproduction company and title, and generated as a new comprehensive feature in the first model. In the second model, we simply used overview as training feature and genres  as labels or document tags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "raw = pd.read_csv('tmdb_5000_credits.csv')\n",
    "data= pd.read_csv('tmdb_5000_movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the cast list from 'tmdb_5000_credits.csv'\n",
    "# Find the length of the cast list\n",
    "def count_cast(string):\n",
    "    count_name = string.count('name')\n",
    "    return count_name\n",
    "# Every name locates between the tag 'name' and 'order', this fuction is to find the index of each tag\n",
    "def findStr(string, subStr, findCnt):\n",
    "    listStr = string.split(subStr,findCnt)\n",
    "    if len(listStr) <= findCnt:\n",
    "        return -1\n",
    "    return len(string)-len(listStr[-1])-len(subStr)\n",
    "# Extract every name in the long messy list\n",
    "raw = raw.assign(cast_list=\"\")\n",
    "for n in range(len(raw)):\n",
    "    cast = ''\n",
    "    allname = raw['cast'].iloc[n]\n",
    "    \n",
    "    for i in range(1,count_cast(allname)+1):\n",
    "        name = findStr(allname,'name',i)\n",
    "        order = findStr(allname,'order',i)  \n",
    "        cast = cast + allname[name+8:order-4]+', '        \n",
    "    raw['cast_list'].iloc[n] = cast\n",
    "    \n",
    "raw = raw.drop(['cast'], axis = 1)\n",
    "raw.to_csv(\"cleaned credits.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'tmdb_5000_credits.csv' data format\n",
    "def moviewords(col):\n",
    "    new_col=[]\n",
    "    for i in data[col]:\n",
    "        i=str(i)\n",
    "        i=i.lower()\n",
    "        i=re.sub('[0-9]', '', i)\n",
    "        i=re.sub('name|id', '', i)\n",
    "        i=re.sub('{\"\": , \"\": \"|\"}', '', i)\n",
    "        i=re.sub('\\\\[|\\\\]', '', i)\n",
    "        i=re.sub('{\"\": \"|\", \"\": }', '', i)\n",
    "        new_col.append(i)\n",
    "    return new_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modified data frame\n",
    "modify=data[['id', 'title', 'overview', 'popularity', 'budget', 'revenue',\n",
    "             'runtime', 'vote_average', 'vote_count']]\n",
    "\n",
    "modify['cast']=raw['cast_list'] #extract cast list from the 1st dataset\n",
    "modify['genres']=moviewords('genres') #format genres\n",
    "modify['keywords']=moviewords('keywords') #format keywords\n",
    "modify['production_companies']=moviewords('production_companies') #format companies\n",
    "modify['features']=modify['keywords']+modify['production_companies']+modify['genres']+modify['title'] #combine needed features\n",
    "#modify['features']=modify['keywords']+modify['production_companies']+modify['genres']+modify['title']+credit['cast_list']\n",
    "modify['index']=list(range(0, len(modify))) #create movie index for future matrix combine  \n",
    "modify=modify.drop_duplicates() #drop duplicates\n",
    "modify=modify.fillna('') #drop mising value\n",
    "modify['title'] = modify['title'].str.lower() #convert all movie names to lowercases\n",
    "modify.to_csv('modified data.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main function - the user could choose the recommendation list by movies names or a short story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    ans = input('Do you want a recommendation list by two movie names or a story?\\n A.Enter movie names   B.Enter a story\\n')\n",
    "    if ans == 'A' or ans == 'a':\n",
    "        overall_recommendation()\n",
    "    if ans == 'B' or ans == 'b': \n",
    "        common_recom()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This whole recommendation system was first designed as an assembly of three models: clustering model based on numerical data columns, Cosine Similarity model based on overall features, and Doc2Vec model based on overview. Although we ended up using only Cosine Similarity model and Doc2Vec, we have tried various approaches, with different features. Below is a brief walk-through for what we did for each of the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine similarity model - Movie recommendation by entering movie names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosine similarity model is based on the Euclidean dot product formula. The idea of the cosine similarity model is to compare the word similarity between two vectors that are converted by words features. At first, we choose cast, crew, title, genres, keywords, and production companies as our overall features to perform cosine similarity model, while the returning label is movie title. However, as the model gives the feedback, the return label is out of our interpretation. The main reason for unexpected label is that even for series movies the cast and crew features can be various. Thus, we decide to remove cast and crew. The new model gives us a good feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cosine similarity between the two input movies\n",
    "def movie_similar(movie_names):\n",
    "    \n",
    "    movie_1=modify[modify['title']==movie_names[0]]\n",
    "    movie_2=modify[modify['title']==movie_names[1]]\n",
    "    movies_df=pd.concat([movie_1, movie_2], axis=0)\n",
    "    count_matrix=CountVectorizer().fit_transform(movies_df['features'])\n",
    "    cosine_sim=np.round(cosine_similarity(count_matrix), 3)\n",
    "    sim=cosine_sim[0,1]\n",
    "    print('movie similarity: ', sim)\n",
    "    print('\\n')\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the input movies are pretty similar, return to the recommendation list based on common features\n",
    "def common_recom(movie_names):\n",
    "    common=modify\n",
    "    movie_1=common[common['title']==movie_names[0]]\n",
    "    movie_2=common[common['title']==movie_names[1]]\n",
    "    common_in_movies=pd.concat([movie_1, movie_2], ignore_index=True)\n",
    "    common.features[len(common)]=common_in_movies.features[0]+''+common_in_movies.features[1]\n",
    "    \n",
    "    count_matrix=CountVectorizer().fit_transform(common['features'])\n",
    "    cosine_sim=np.round(cosine_similarity(count_matrix), 3)\n",
    "    \n",
    "    index=4803\n",
    "    similar_movies=list(enumerate(cosine_sim[index]))\n",
    "    similar_movies=pd.DataFrame(similar_movies, columns=['index', 'similarity'])\n",
    "    similar_movies=pd.merge(similar_movies, common[['index', 'title','popularity','vote_average']], on='index')\n",
    "    def similar_movies_index(title):\n",
    "        return similar_movies.index[similar_movies['title']==title].values[0]\n",
    "    similar_movies=similar_movies.drop(index=[similar_movies_index(movie_names[0]),\n",
    "                                        similar_movies_index(movie_names[1])])\n",
    "    similar_movies=similar_movies.sort_values(by='similarity', ascending=False)\n",
    "    similar_movies=similar_movies[0:10]\n",
    "    print('recommendation by commonplace')\n",
    "    print(similar_movies.sort_values(by = 'popularity',ascending = False))\n",
    "    print('\\n')\n",
    "    return similar_movies.sort_values(by = 'popularity',ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If input movies are not similar, seperate movie recommendation\n",
    "def movie_recom(movie_names):\n",
    "    count_matrix=CountVectorizer().fit_transform(modify['features'])\n",
    "    cosine_sim=np.round(cosine_similarity(count_matrix), 3)\n",
    "    def movie_index(title):\n",
    "        return modify.index[modify['title']==title].values[0]\n",
    "    for movie_name in movie_names:\n",
    "        index=movie_index(movie_name)\n",
    "        similar_movies=list(enumerate(cosine_sim[index]))\n",
    "        similar_movies=pd.DataFrame(similar_movies, columns=['index', 'similarity'])\n",
    "        similar_movies=pd.merge(similar_movies, modify[['index', 'title','popularity','vote_average']], on='index')\n",
    "        similar_movies=similar_movies.sort_values(by='similarity', ascending=False)\n",
    "        similar_movies = similar_movies[1:10]\n",
    "        print('recommendation for ', movie_name)\n",
    "        print(similar_movies.sort_values(by = 'popularity',ascending = False))\n",
    "        print('\\n')\n",
    "    return similar_movies.sort_values(by = 'popularity',ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the above situation and provide an overall recommendation\n",
    "def overall_recommendation():\n",
    "    movie01 = str(input('Please enter the 1st movie:\\n')).lower()\n",
    "    movie02 = str(input('Please enter the 2nd movie:\\n')).lower()\n",
    "    movie_names = [movie01, movie02]\n",
    "    if movie_similar(movie_names) > 0.15:\n",
    "        common_recom(movie_names)\n",
    "    else:\n",
    "        movie_recom(movie_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter the 1st movie:\n",
      "Spider-Man\n",
      "Please enter the 2nd movie:\n",
      "the avengers\n",
      "movie similarity:  0.374\n",
      "\n",
      "\n",
      "recommendation by commonplace\n",
      "     index  similarity                                title  popularity  \\\n",
      "26      26       0.481           captain america: civil war  198.372395   \n",
      "7        7       0.553              avengers: age of ultron  134.279229   \n",
      "68      68       0.470                             iron man  120.725053   \n",
      "182    182       0.663                              ant-man  120.093610   \n",
      "126    126       0.535                 thor: the dark world   99.499595   \n",
      "129    129       0.516                                 thor   86.493424   \n",
      "79      79       0.592                           iron man 2   77.300194   \n",
      "85      85       0.503  captain america: the winter soldier   72.225265   \n",
      "174    174       0.535                  the incredible hulk   62.898336   \n",
      "203    203       0.463                                   x2    2.871739   \n",
      "\n",
      "     vote_average  \n",
      "26            7.1  \n",
      "7             7.3  \n",
      "68            7.4  \n",
      "182           7.0  \n",
      "126           6.8  \n",
      "129           6.6  \n",
      "79            6.6  \n",
      "85            7.6  \n",
      "174           6.1  \n",
      "203           6.8  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model test\n",
    "overall_recommendation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2Vec - Movie recommendation by entering keywords or stories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When training this model and deciding the best parameters, we set up three models with different parameters, for example learning rate, vector size, max number of iterations, etc. To pick model that performs the best, we simply used human interpretability to determine whether the results make sense. And we found the default model has the highest performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv(\"modified data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean stopwords and punctuation and to lowercase training data (overview and genres)\n",
    "def token_clean(name):\n",
    "    lemma = nltk.wordnet.WordNetLemmatizer()\n",
    "    name_list = []\n",
    "    movies[name] = movies[name].astype(str)\n",
    "    for index,row in movies.iterrows():\n",
    "        text = row[name]\n",
    "        text = re.sub(r'\\b\\d+\\b', '', text)\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        tokens = [token.lower() for token in tokens if token.lower() not in stopwords.words('english')]\n",
    "        tokens = [term for term in tokens if term not in string.punctuation]\n",
    "        tokens = [lemma.lemmatize(token) for token in tokens]\n",
    "        new_fea = ' '.join(tokens)\n",
    "        name_list.append(new_fea)\n",
    "    return name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "overview = token_clean(\"overview\")\n",
    "genres = token_clean(\"genres\")\n",
    "movies[\"genres\"] = genres\n",
    "data = overview\n",
    "tags = genres\n",
    "tagged_data = [TaggedDocument(words=nltk.word_tokenize(d), tags=nltk.word_tokenize(str(tags[i]))) for i, d in enumerate(data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 100\n",
    "\n",
    "model = Doc2Vec(size=20, alpha=0.025,  min_alpha=0.00025, min_count=1, dm =1) # low performance\n",
    "\n",
    "model1 = Doc2Vec(dm=0, vector_size=100, negative=5, hs=0, min_count=2, sample=0,  epochs=20) # decided model\n",
    "\n",
    "model2 = Doc2Vec(dm=1, vector_size=100, window=10, negative=5, hs=0, min_count=2, sample=0, \n",
    "                 epochs=20, alpha=0.05, comment='alpha=0.05') #low performance\n",
    "\n",
    "model3 = Doc2Vec(dm=1, dm_concat=1, vector_size=100, window=5, negative=5, hs=0, min_count=2, sample=0, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 20\n",
      "iteration 21\n",
      "iteration 22\n",
      "iteration 23\n",
      "iteration 24\n",
      "iteration 25\n",
      "iteration 26\n",
      "iteration 27\n",
      "iteration 28\n",
      "iteration 29\n",
      "iteration 30\n",
      "iteration 31\n",
      "iteration 32\n",
      "iteration 33\n",
      "iteration 34\n",
      "iteration 35\n",
      "iteration 36\n",
      "iteration 37\n",
      "iteration 38\n",
      "iteration 39\n",
      "iteration 40\n",
      "iteration 41\n",
      "iteration 42\n",
      "iteration 43\n",
      "iteration 44\n",
      "iteration 45\n",
      "iteration 46\n",
      "iteration 47\n",
      "iteration 48\n",
      "iteration 49\n",
      "iteration 50\n",
      "iteration 51\n",
      "iteration 52\n",
      "iteration 53\n",
      "iteration 54\n",
      "iteration 55\n",
      "iteration 56\n",
      "iteration 57\n",
      "iteration 58\n",
      "iteration 59\n",
      "iteration 60\n",
      "iteration 61\n",
      "iteration 62\n",
      "iteration 63\n",
      "iteration 64\n",
      "iteration 65\n",
      "iteration 66\n",
      "iteration 67\n",
      "iteration 68\n",
      "iteration 69\n",
      "iteration 70\n",
      "iteration 71\n",
      "iteration 72\n",
      "iteration 73\n",
      "iteration 74\n",
      "iteration 75\n",
      "iteration 76\n",
      "iteration 77\n",
      "iteration 78\n",
      "iteration 79\n",
      "iteration 80\n",
      "iteration 81\n",
      "iteration 82\n",
      "iteration 83\n",
      "iteration 84\n",
      "iteration 85\n",
      "iteration 86\n",
      "iteration 87\n",
      "iteration 88\n",
      "iteration 89\n",
      "iteration 90\n",
      "iteration 91\n",
      "iteration 92\n",
      "iteration 93\n",
      "iteration 94\n",
      "iteration 95\n",
      "iteration 96\n",
      "iteration 97\n",
      "iteration 98\n",
      "iteration 99\n",
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "model1.build_vocab(tagged_data)\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    print('iteration {0}'.format(epoch))\n",
    "    model1.train(tagged_data,\n",
    "                total_examples=model1.corpus_count,\n",
    "                epochs=model1.iter)\n",
    "    # decrease the learning rate\n",
    "    model1.alpha -= 0.0002\n",
    "    # fix the learning rate, no decay\n",
    "    model1.min_alpha = model1.alpha\n",
    "model1.save(\"d2v.model1\")\n",
    "print(\"Model Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('science', 0.5613155364990234), ('fiction', 0.5505940318107605), ('fantasy', 0.3485146164894104), ('adventure', 0.34481221437454224), ('action', 0.3408849835395813)]\n"
     ]
    }
   ],
   "source": [
    "# test overview of Avatar\n",
    "model= Doc2Vec.load(\"d2v.model1\")\n",
    "test_data = word_tokenize(\n",
    "    '22nd century paraplegic marine dispatched moon pandora unique mission becomes torn following order protecting alien civilization'.lower())\n",
    "v1 = model.infer_vector(test_data)\n",
    "\n",
    "print(model.docvecs.most_similar(positive=[v1], topn = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'science fiction fantasy'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract top n most similar genres\n",
    "def similar_genres(overview, n = 3):\n",
    "    g = ''\n",
    "    model= Doc2Vec.load(\"d2v.model1\")\n",
    "    test_data = word_tokenize(overview.lower())\n",
    "    v1 = model.infer_vector(test_data)\n",
    "    genres = model.docvecs.most_similar(positive=[v1], topn = n)\n",
    "    for i in genres:\n",
    "        g = g+ \" \" + i[0]\n",
    "    g = g.strip()\n",
    "    return g\n",
    "\n",
    "# test function\n",
    "similar_genres(\n",
    "    '22nd century paraplegic marine dispatched moon pandora unique mission becomes torn following order protecting alien civilization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter story: A young man and a young woman fell in love\n",
      "romance fantasy movie tv thriller\n",
      "      index  similarity                                 title  popularity  \\\n",
      "100     100       0.600   the curious case of benjamin button   60.269279   \n",
      "2108   2108       0.516                   edward scissorhands   47.513630   \n",
      "1132   1132       0.516                       red riding hood   45.151657   \n",
      "2017   2017       0.600                                 ghost   41.967005   \n",
      "295     295       0.516                           the tourist   41.426678   \n",
      "2438   2438       0.671                       the illusionist   36.960953   \n",
      "2441   2441       0.632                escobar: paradise lost   25.112567   \n",
      "2685   2685       0.516              exorcist ii: the heretic   11.543363   \n",
      "3907   3907       0.516  jason goes to hell: the final friday   10.341982   \n",
      "3803   3803       0.632                           inescapable    6.783053   \n",
      "4289   4289       0.516               da sweet blood of jesus    4.480579   \n",
      "1669   1669       0.600                           the promise    3.866026   \n",
      "1449   1449       0.548                             the order    3.746806   \n",
      "3809   3809       0.671                   how to fall in love    1.923514   \n",
      "4756   4756       0.516                   the call of cthulhu    1.777148   \n",
      "4056   4056       0.632                          impact point    1.532518   \n",
      "4800   4800       0.600             signed, sealed, delivered    1.444476   \n",
      "3285   3285       0.671                              restless    0.812776   \n",
      "3655   3655       0.632                           fascination    0.219799   \n",
      "3665   3665       0.600                  we have your husband    0.102003   \n",
      "\n",
      "      vote_average  \n",
      "100            7.3  \n",
      "2108           7.5  \n",
      "1132           5.6  \n",
      "2017           6.9  \n",
      "295            6.0  \n",
      "2438           7.1  \n",
      "2441           6.1  \n",
      "2685           4.5  \n",
      "3907           4.2  \n",
      "3803           5.2  \n",
      "4289           4.1  \n",
      "1669           5.0  \n",
      "1449           4.8  \n",
      "3809           5.2  \n",
      "4756           6.9  \n",
      "4056           5.7  \n",
      "4800           7.0  \n",
      "3285           4.9  \n",
      "3655           3.8  \n",
      "3665           5.0  \n"
     ]
    }
   ],
   "source": [
    "# Movie recommendation based on common features\n",
    "def common_recom(n=5):\n",
    "    overview = input(\"Enter story: \")\n",
    "    common=movies\n",
    "    common.genres[len(common)]=similar_genres(overview, n)\n",
    "    common.reset_index()\n",
    "    \n",
    "    count_matrix=CountVectorizer().fit_transform(common['genres'])\n",
    "    cosine_sim=np.round(cosine_similarity(count_matrix), 3)\n",
    "    \n",
    "    index=len(common.genres)-1\n",
    "    similar_movies=list(enumerate(cosine_sim[index]))\n",
    "    similar_movies=pd.DataFrame(similar_movies, columns=['index', 'similarity'])\n",
    "    similar_movies=pd.merge(similar_movies, common[['index', 'title', 'popularity', 'vote_average']], on='index')\n",
    "    \n",
    "    similar_movies=similar_movies.sort_values(by='similarity', ascending=False)[:20]\n",
    "    similar_movies=similar_movies.sort_values(by='popularity', ascending=False)\n",
    "    #print('recommendation by commonplace')\n",
    "    #print(similar_movies[0:20])\n",
    "    #print('\\n')\n",
    "    print(similar_genres(overview, n))\n",
    "    print(similar_movies[0:20])\n",
    "\n",
    "# Test function with a short story\n",
    "common_recom()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering model - discarded for final output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main idea of applying clustering model to numeric variables is to determine whether there are distinct divides of movies based on their different parameters, such as “Budget”, and “Vote_average”. In our case, we used KMeans clustering; however, the result is not promising. Although the Silhouette Scores for models with different “K’s” are ok, we can not come to an appropriate interpretation for each cluster. Especially, the system we are trying to build here is to recommend movies based on their story and genres. Hence, we have no choice but to remove this model from our final output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimension reduction\n",
    "movies_clu = pd.read_csv(\"modified data.csv\")\n",
    "movies_clu = movies_clu[[\"title\", \"popularity\", \"budget\", \"revenue\", \"runtime\", \"vote_average\"]]\n",
    "movies_clu.index = movies_clu.title\n",
    "movies_clu = movies_clu[[\"budget\", \"vote_average\"]]\n",
    "\n",
    "#normalize data to one or two digits\n",
    "movies_clu[\"budget\"] = movies_clu[\"budget\"]/1000000\n",
    "movies_clu[\"vote_average\"] = movies_clu[\"vote_average\"]*10\n",
    "#movies_clu[\"revenue\"] = movies_clu[\"revenue\"]/1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'SSE')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# elbow graph for different number of clusters\n",
    "sse = {}\n",
    "data_clu = movies_clu\n",
    "for k in range(2, 9):\n",
    "    kmeans = KMeans(n_clusters=k, max_iter=1000).fit(data_clu)\n",
    "    data_clu[\"clusters\"] = kmeans.labels_\n",
    "    #print(data[\"clusters\"])\n",
    "    sse[k] = kmeans.inertia_ # Inertia: Sum of distances of samples to their closest cluster center\n",
    "fig = plt.figure()\n",
    "plt.plot(list(sse.keys()), list(sse.values()))\n",
    "plt.xlabel(\"Number of cluster\")\n",
    "plt.ylabel(\"SSE\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters from 2 to 9: \n",
      " [2, 3, 4, 5, 6, 7, 8, 9]\n",
      "For n_clusters = 2, silhouette score is 0.6716407108832871)\n",
      "For n_clusters = 3, silhouette score is 0.5723511781979906)\n",
      "For n_clusters = 4, silhouette score is 0.456040665546396)\n",
      "For n_clusters = 5, silhouette score is 0.43136673574531464)\n",
      "For n_clusters = 6, silhouette score is 0.4340383083279029)\n",
      "For n_clusters = 7, silhouette score is 0.43245274124133)\n",
      "For n_clusters = 8, silhouette score is 0.4377027633601434)\n",
      "For n_clusters = 9, silhouette score is 0.4218794198123789)\n"
     ]
    }
   ],
   "source": [
    "# evaluating number of clusters\n",
    "range_n_clusters = list (range(2,10))\n",
    "print (\"Number of clusters from 2 to 9: \\n\", range_n_clusters)\n",
    "\n",
    "for n in range_n_clusters:\n",
    "    clusterer = KMeans(n_clusters=n).fit(data_clu)\n",
    "    preds = clusterer.predict(data_clu)\n",
    "\n",
    "    score = silhouette_score(data_clu, preds, metric='euclidean')\n",
    "    print (\"For n_clusters = {}, silhouette score is {})\".format(n, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want a recommendation list by two movie names or a story?\n",
      " A.Enter movie names   B.Enter a story\n",
      "A\n",
      "Please enter the 1st movie:\n",
      "Iron Man\n",
      "Please enter the 2nd movie:\n",
      "Star Wars\n",
      "movie similarity:  0.031\n",
      "\n",
      "\n",
      "recommendation for  iron man\n",
      "     index  similarity                                title  popularity  \\\n",
      "16      16       0.507                         the avengers  144.448633   \n",
      "7        7       0.493              avengers: age of ultron  134.279229   \n",
      "182    182       0.649                              ant-man  120.093610   \n",
      "126    126       0.520                 thor: the dark world   99.499595   \n",
      "129    129       0.471                                 thor   86.493424   \n",
      "31      31       0.688                           iron man 3   77.682080   \n",
      "79      79       0.649                           iron man 2   77.300194   \n",
      "85      85       0.500  captain america: the winter soldier   72.225265   \n",
      "174    174       0.440                  the incredible hulk   62.898336   \n",
      "\n",
      "     vote_average  \n",
      "16            7.4  \n",
      "7             7.3  \n",
      "182           7.0  \n",
      "126           6.8  \n",
      "129           6.6  \n",
      "31            6.8  \n",
      "79            6.6  \n",
      "85            7.6  \n",
      "174           6.1  \n",
      "\n",
      "\n",
      "recommendation for  star wars\n",
      "      index  similarity                                         title  \\\n",
      "0         0       0.297                                        avatar   \n",
      "1990   1990       0.542                       the empire strikes back   \n",
      "233     233       0.310     star wars: episode i - the phantom menace   \n",
      "1490   1490       0.445                            return of the jedi   \n",
      "230     230       0.335  star wars: episode ii - attack of the clones   \n",
      "3899   3899       0.292                beneath the planet of the apes   \n",
      "4176   4176       0.286             battle for the planet of the apes   \n",
      "966     966       0.298                                     marmaduke   \n",
      "4184   4184       0.298                             deadline - u.s.a.   \n",
      "\n",
      "      popularity  vote_average  \n",
      "0     150.437577           7.2  \n",
      "1990   78.517830           8.2  \n",
      "233    54.035265           6.3  \n",
      "1490   46.509071           7.9  \n",
      "230    43.987061           6.4  \n",
      "3899   24.393296           6.2  \n",
      "4176   13.315383           5.5  \n",
      "966    12.256220           5.0  \n",
      "4184    0.225627           6.9  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want a recommendation list by two movie names or a story?\n",
      " A.Enter movie names   B.Enter a story\n",
      "B\n",
      "Enter story: you jump I jump\n",
      "science fiction horror adventure family\n",
      "      index  similarity                                    title  popularity  \\\n",
      "87       87       0.800                             tomorrowland  130.311355   \n",
      "2285   2285       0.800                       back to the future   76.603233   \n",
      "2967   2967       0.800               e.t. the extra-terrestrial   56.105798   \n",
      "1068   1068       0.800     the hitchhiker's guide to the galaxy   51.742065   \n",
      "358     358       0.800                atlantis: the lost empire   51.548589   \n",
      "1165   1165       0.800              back to the future part iii   45.769562   \n",
      "1152   1152       0.800               back to the future part ii   43.345252   \n",
      "67       67       0.800                       monsters vs aliens   36.167578   \n",
      "778     778       0.800                                meet dave   18.676291   \n",
      "461     461       0.894                            lost in space   17.455024   \n",
      "2755   2755       0.894                            earth to echo   17.371327   \n",
      "661     661       0.800               zathura: a space adventure   15.194239   \n",
      "960     960       0.894  the adventures of sharkboy and lavagirl   12.311010   \n",
      "3405   3405       0.775               stargate: the ark of truth    8.591387   \n",
      "2129   2129       0.800                           the black hole    8.265317   \n",
      "1093   1093       0.800                              deep rising    6.513856   \n",
      "1794   1794       0.800                            clockstoppers    5.894163   \n",
      "4344   4344       0.800                            godzilla 2000    3.322721   \n",
      "799     799       0.800                 resident evil: afterlife    2.143764   \n",
      "4669   4669       0.894            the beast from 20,000 fathoms    2.043661   \n",
      "\n",
      "      vote_average  \n",
      "87             6.2  \n",
      "2285           8.0  \n",
      "2967           7.3  \n",
      "1068           6.6  \n",
      "358            6.7  \n",
      "1165           7.1  \n",
      "1152           7.4  \n",
      "67             6.0  \n",
      "778            5.0  \n",
      "461            5.0  \n",
      "2755           5.7  \n",
      "661            6.1  \n",
      "960            4.4  \n",
      "3405           6.9  \n",
      "2129           6.1  \n",
      "1093           6.0  \n",
      "1794           4.9  \n",
      "4344           5.9  \n",
      "799            5.8  \n",
      "4669           6.7  \n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, both methods can generate reasonably similar movies. Cosine Similarity based model performs really well when two input movies are close in terms of cosine or similar. For example, when they are all about superheros. However, when two input movies are very different from each other, the performance  of finding similar movies to both inputs dropped, and that is why we took another path to return similar movies to each input. For the second method which applies Doc2Vec, it sometimes can provide surprisingly precise result, but the performance is not consistent. For example, when “alien” is in the input overview, the program will consider it as genres of “fiction”, “science”, and “thriller” and return movies like “Independence Day” and “Star Trek”. Given “alien” is not a tagged genres, the result is surprising.\n",
    "    \n",
    "But of course, there are some weaknesses in our model. For example, since the keywords, the most important feature, is concluded by viewers without a standard, some similar movies might have very different keywords due to the different focus by viewers. As a result, the similarity score between some similar movies could be very low. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our system has genres recommendation bias problem. The system performs better in recommending fiction and action movies. However, for the other genres, the results are not very accurate. For objective feature bias, we might add more features, such as movie director and main cast, by which the significance of certain feature, in this case keywords, would decrease and the cosine similarity model would have a better performance. Moreover, one of the reasons of low accuracy recommendation in other genres is insufficient data set. The lack of data diversity and adequacy cause recommendation bias problem. Therefore, we can also feed more data to train Doc2Vec model. For this project, we only used movie overviews to train our model, but for future work, the whole movie script can be used, and ideally generate better performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
